#!/usr/bin/env python3

"""
è®­ç»ƒæµæ°´çº¿ - ç»Ÿä¸€çš„å››é˜¶æ®µè®­ç»ƒæµç¨‹ç®¡ç†
"""

import logging
import time
from typing import Dict, Any, Optional, List, Callable
from pathlib import Path
from dataclasses import dataclass
from enum import Enum
import json

from .base_trainer import TrainingStage, TrainingResult, TrainingProgressCallback
from .environment_factory import EnvironmentFactory
from .model_transfer import ModelTransferManager

logger = logging.getLogger(__name__)


class PipelineStatus(Enum):
    """æµæ°´çº¿çŠ¶æ€"""
    IDLE = "idle"
    PREPARING = "preparing"
    FOUNDATION_TRAINING = "foundation_training"
    TRANSFERRING = "transferring"
    BRANCH_TRAINING = "branch_training"
    EVALUATING = "evaluating"
    COMPLETED = "completed"
    FAILED = "failed"


@dataclass
class PipelineConfig:
    """æµæ°´çº¿é…ç½®"""
    # åŸºç¡€é…ç½®
    experiment_name: str = "hauav_pipeline"
    output_dir: str = "./experiments"
    log_level: str = "INFO"
    
    # Foundationé˜¶æ®µé…ç½®
    foundation_config: Dict[str, Any] = None
    foundation_trainer_class: str = "BaseFlightTrainer"
    
    # åˆ†æ”¯è®­ç»ƒé…ç½®
    branches_config: Dict[str, Dict[str, Any]] = None
    enable_parallel_branches: bool = False
    
    # è¿ç§»é…ç½®
    transfer_config: Dict[str, Any] = None
    
    # è¯„ä¼°é…ç½®
    evaluation_config: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.foundation_config is None:
            self.foundation_config = {}
        if self.branches_config is None:
            self.branches_config = {
                "hierarchical": {},
                "ablation": {"ablation_types": ["B1", "B2", "B3"]},
                "baseline": {"algorithms": ["ppo", "sac"]}
            }
        if self.transfer_config is None:
            self.transfer_config = {"transfer_mode": "partial"}
        if self.evaluation_config is None:
            self.evaluation_config = {"eval_episodes": 100}


@dataclass 
class PipelineResult:
    """æµæ°´çº¿ç»“æœ"""
    status: PipelineStatus
    total_duration: float
    foundation_result: Optional[TrainingResult] = None
    branch_results: Dict[str, TrainingResult] = None
    evaluation_results: Dict[str, Any] = None
    error_message: Optional[str] = None
    
    def __post_init__(self):
        if self.branch_results is None:
            self.branch_results = {}


class TrainingPipeline:
    """
    è®­ç»ƒæµæ°´çº¿ - ç¼–æ’å››é˜¶æ®µè®­ç»ƒæµç¨‹
    
    Foundation â†’ (Hierarchical | Ablation | Baseline)
    """
    
    def __init__(self, 
                 config: PipelineConfig,
                 environment_factory: Optional[EnvironmentFactory] = None,
                 model_transfer_manager: Optional[ModelTransferManager] = None):
        
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(getattr(logging, config.log_level.upper()))
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.env_factory = environment_factory or EnvironmentFactory()
        self.transfer_manager = model_transfer_manager or ModelTransferManager()
        
        # çŠ¶æ€ç®¡ç†
        self.status = PipelineStatus.IDLE
        self.start_time = None
        self.foundation_checkpoint = None
        
        # ç»“æœå­˜å‚¨
        self.experiment_dir = Path(config.output_dir) / config.experiment_name
        self.experiment_dir.mkdir(parents=True, exist_ok=True)
        
        # å›è°ƒå‡½æ•°
        self.progress_callbacks: List[Callable] = []
        
        # è®­ç»ƒå™¨å®ä¾‹ç¼“å­˜
        self._trainer_cache = {}
    
    def add_progress_callback(self, callback: Callable) -> None:
        """æ·»åŠ è¿›åº¦å›è°ƒå‡½æ•°"""
        self.progress_callbacks.append(callback)
    
    def run_pipeline(self) -> PipelineResult:
        """
        æ‰§è¡Œå®Œæ•´çš„è®­ç»ƒæµæ°´çº¿
        
        Returns:
            æµæ°´çº¿æ‰§è¡Œç»“æœ
        """
        
        self.start_time = time.time()
        self.status = PipelineStatus.PREPARING
        
        try:
            # 1. å‡†å¤‡é˜¶æ®µ
            self._notify_progress("å¼€å§‹è®­ç»ƒæµæ°´çº¿", {"stage": "preparation"})
            self._prepare_pipeline()
            
            # 2. Foundationè®­ç»ƒ
            self.status = PipelineStatus.FOUNDATION_TRAINING
            self._notify_progress("å¼€å§‹åŸºåº§æ¨¡å‹è®­ç»ƒ", {"stage": "foundation"})
            foundation_result = self._run_foundation_training()
            
            # 3. æ¨¡å‹è¿ç§»å‡†å¤‡
            self.status = PipelineStatus.TRANSFERRING
            self._notify_progress("å‡†å¤‡æ¨¡å‹è¿ç§»", {"stage": "transfer"})
            self._prepare_model_transfer()
            
            # 4. åˆ†æ”¯è®­ç»ƒ
            self.status = PipelineStatus.BRANCH_TRAINING
            self._notify_progress("å¼€å§‹åˆ†æ”¯è®­ç»ƒ", {"stage": "branches"})
            branch_results = self._run_branch_training()
            
            # 5. è¯„ä¼°é˜¶æ®µ
            self.status = PipelineStatus.EVALUATING
            self._notify_progress("å¼€å§‹è¯„ä¼°", {"stage": "evaluation"})
            evaluation_results = self._run_evaluation(branch_results)
            
            # 6. å®Œæˆ
            self.status = PipelineStatus.COMPLETED
            total_duration = time.time() - self.start_time
            
            result = PipelineResult(
                status=self.status,
                total_duration=total_duration,
                foundation_result=foundation_result,
                branch_results=branch_results,
                evaluation_results=evaluation_results
            )
            
            self._save_pipeline_result(result)
            self._notify_progress("æµæ°´çº¿å®Œæˆ", {"duration": total_duration})
            
            return result
            
        except Exception as e:
            self.status = PipelineStatus.FAILED
            error_duration = time.time() - self.start_time if self.start_time else 0
            
            error_result = PipelineResult(
                status=self.status,
                total_duration=error_duration,
                error_message=str(e)
            )
            
            self.logger.error(f"æµæ°´çº¿æ‰§è¡Œå¤±è´¥: {e}")
            self._notify_progress("æµæ°´çº¿å¤±è´¥", {"error": str(e)})
            
            return error_result
    
    def _prepare_pipeline(self) -> None:
        """å‡†å¤‡æµæ°´çº¿æ‰§è¡Œç¯å¢ƒ"""
        
        # åˆ›å»ºå®éªŒç›®å½•ç»“æ„
        (self.experiment_dir / "models").mkdir(exist_ok=True)
        (self.experiment_dir / "logs").mkdir(exist_ok=True)
        (self.experiment_dir / "evaluations").mkdir(exist_ok=True)
        (self.experiment_dir / "configs").mkdir(exist_ok=True)
        
        # ä¿å­˜é…ç½®æ–‡ä»¶
        config_path = self.experiment_dir / "configs" / "pipeline_config.json"
        with open(config_path, 'w') as f:
            # ç®€åŒ–é…ç½®ä»¥ä¾¿JSONåºåˆ—åŒ–
            config_dict = {
                'experiment_name': self.config.experiment_name,
                'output_dir': self.config.output_dir,
                'foundation_config': self.config.foundation_config,
                'branches_config': self.config.branches_config,
                'transfer_config': self.config.transfer_config,
                'evaluation_config': self.config.evaluation_config
            }
            json.dump(config_dict, f, indent=2)
        
        # éªŒè¯ç¯å¢ƒå¯ç”¨æ€§
        for stage in [TrainingStage.FOUNDATION, TrainingStage.HIERARCHICAL, 
                     TrainingStage.ABLATION, TrainingStage.BASELINE]:
            
            env = self.env_factory.create_environment(stage, {}, mode="train")
            is_valid = self.env_factory.validate_environment(env, stage)
            
            if not is_valid:
                raise RuntimeError(f"ç¯å¢ƒéªŒè¯å¤±è´¥: {stage.value}")
        
        self.logger.info("æµæ°´çº¿å‡†å¤‡å®Œæˆ")
    
    def _run_foundation_training(self) -> TrainingResult:
        """æ‰§è¡ŒåŸºåº§æ¨¡å‹è®­ç»ƒ"""
        
        # åŠ¨æ€åŠ è½½Foundationè®­ç»ƒå™¨
        trainer_class = self._load_trainer_class(
            self.config.foundation_trainer_class,
            TrainingStage.FOUNDATION
        )
        
        # åˆ›å»ºè®­ç»ƒå™¨å®ä¾‹
        trainer = trainer_class(
            config=self.config.foundation_config,
            env_factory=self.env_factory,
            output_dir=str(self.experiment_dir / "models")
        )
        
        # æ·»åŠ è¿›åº¦å›è°ƒ
        if hasattr(trainer, 'add_progress_callback'):
            trainer.add_progress_callback(
                lambda stage, progress: self._notify_progress(
                    f"Foundationè®­ç»ƒè¿›åº¦: {progress.get('episode', 0)}", 
                    progress
                )
            )
        
        # æ‰§è¡Œè®­ç»ƒ
        foundation_result = trainer.train()
        
        # ä¿å­˜åŸºåº§æ¨¡å‹
        if foundation_result.success:
            model_path = self.transfer_manager.save_foundation_model(
                model=foundation_result.trained_model,
                optimizer=foundation_result.metadata.get('optimizer'),
                training_stats=foundation_result.metadata.get('training_stats', {}),
                model_name=f"{self.config.experiment_name}_foundation"
            )
            
            # åŠ è½½checkpointç”¨äºåç»­è¿ç§»
            self.foundation_checkpoint = self.transfer_manager.load_foundation_model(model_path)
            
            self.logger.info(f"åŸºåº§æ¨¡å‹è®­ç»ƒå®Œæˆ: {model_path}")
        else:
            raise RuntimeError(f"åŸºåº§æ¨¡å‹è®­ç»ƒå¤±è´¥: {foundation_result.error_message}")
        
        return foundation_result
    
    def _prepare_model_transfer(self) -> None:
        """å‡†å¤‡æ¨¡å‹è¿ç§»"""
        
        if self.foundation_checkpoint is None:
            raise RuntimeError("åŸºåº§æ¨¡å‹æœªå°±ç»ªï¼Œæ— æ³•è¿›è¡Œè¿ç§»")
        
        # éªŒè¯è¿ç§»å…¼å®¹æ€§
        for branch_name in self.config.branches_config.keys():
            if branch_name == "hierarchical":
                target_stage = TrainingStage.HIERARCHICAL
            elif branch_name == "ablation":
                target_stage = TrainingStage.ABLATION
            elif branch_name == "baseline":
                target_stage = TrainingStage.BASELINE
            else:
                continue
            
            # åˆ›å»ºç›®æ ‡æ¨¡å‹ç¤ºä¾‹ç”¨äºå…¼å®¹æ€§æ£€æŸ¥
            # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„æ¨¡å‹ç±»è¿›è¡Œå®ä¾‹åŒ–
            # æš‚æ—¶è·³è¿‡è¯¦ç»†æ£€æŸ¥
            self.logger.info(f"è¿ç§»å…¼å®¹æ€§æ£€æŸ¥é€šè¿‡: {branch_name}")
        
        self.logger.info("æ¨¡å‹è¿ç§»å‡†å¤‡å®Œæˆ")
    
    def _run_branch_training(self) -> Dict[str, TrainingResult]:
        """æ‰§è¡Œåˆ†æ”¯è®­ç»ƒ"""
        
        branch_results = {}
        
        if self.config.enable_parallel_branches:
            # å¹¶è¡Œåˆ†æ”¯è®­ç»ƒ (å¤æ‚å®ç°ï¼Œæš‚æ—¶ä¸²è¡Œ)
            self.logger.warning("å¹¶è¡Œåˆ†æ”¯è®­ç»ƒæš‚æœªå®ç°ï¼Œä½¿ç”¨ä¸²è¡Œæ¨¡å¼")
        
        # ä¸²è¡Œåˆ†æ”¯è®­ç»ƒ
        for branch_name, branch_config in self.config.branches_config.items():
            
            self.logger.info(f"å¼€å§‹è®­ç»ƒåˆ†æ”¯: {branch_name}")
            
            try:
                if branch_name == "hierarchical":
                    result = self._train_hierarchical_branch(branch_config)
                elif branch_name == "ablation":
                    result = self._train_ablation_branch(branch_config)
                elif branch_name == "baseline":
                    result = self._train_baseline_branch(branch_config)
                else:
                    self.logger.warning(f"æœªçŸ¥åˆ†æ”¯ç±»å‹: {branch_name}")
                    continue
                
                branch_results[branch_name] = result
                self.logger.info(f"åˆ†æ”¯ {branch_name} è®­ç»ƒå®Œæˆ")
                
            except Exception as e:
                self.logger.error(f"åˆ†æ”¯ {branch_name} è®­ç»ƒå¤±è´¥: {e}")
                # ç»§ç»­è®­ç»ƒå…¶ä»–åˆ†æ”¯
                continue
        
        return branch_results
    
    def _train_hierarchical_branch(self, config: Dict[str, Any]) -> TrainingResult:
        """è®­ç»ƒåˆ†å±‚åˆ†æ”¯"""
        
        # åŠ¨æ€åŠ è½½Hierarchicalè®­ç»ƒå™¨
        trainer_class = self._load_trainer_class("HierarchicalTrainer", TrainingStage.HIERARCHICAL)
        
        trainer = trainer_class(
            config=config,
            env_factory=self.env_factory,
            transfer_manager=self.transfer_manager,
            foundation_checkpoint=self.foundation_checkpoint,
            output_dir=str(self.experiment_dir / "models")
        )
        
        return trainer.train()
    
    def _train_ablation_branch(self, config: Dict[str, Any]) -> TrainingResult:
        """è®­ç»ƒæ¶ˆèåˆ†æ”¯"""
        
        # åŠ¨æ€åŠ è½½Ablationè®­ç»ƒå™¨  
        trainer_class = self._load_trainer_class("AblationTrainer", TrainingStage.ABLATION)
        
        trainer = trainer_class(
            config=config,
            env_factory=self.env_factory,
            transfer_manager=self.transfer_manager,
            foundation_checkpoint=self.foundation_checkpoint,
            output_dir=str(self.experiment_dir / "models")
        )
        
        return trainer.train()
    
    def _train_baseline_branch(self, config: Dict[str, Any]) -> TrainingResult:
        """è®­ç»ƒåŸºçº¿åˆ†æ”¯"""
        
        # åŠ¨æ€åŠ è½½Baselineè®­ç»ƒå™¨
        trainer_class = self._load_trainer_class("BaselineTrainer", TrainingStage.BASELINE)
        
        trainer = trainer_class(
            config=config,
            env_factory=self.env_factory,
            transfer_manager=self.transfer_manager,
            foundation_checkpoint=self.foundation_checkpoint,
            output_dir=str(self.experiment_dir / "models")
        )
        
        return trainer.train()
    
    def _run_evaluation(self, branch_results: Dict[str, TrainingResult]) -> Dict[str, Any]:
        """è¿è¡Œè¯„ä¼°"""
        
        evaluation_results = {}
        
        for branch_name, training_result in branch_results.items():
            if not training_result.success:
                self.logger.warning(f"è·³è¿‡å¤±è´¥åˆ†æ”¯çš„è¯„ä¼°: {branch_name}")
                continue
            
            try:
                # åˆ›å»ºè¯„ä¼°å™¨
                evaluator = self._create_evaluator(branch_name, training_result)
                
                # æ‰§è¡Œè¯„ä¼°
                eval_result = evaluator.evaluate(
                    episodes=self.config.evaluation_config.get('eval_episodes', 100)
                )
                
                evaluation_results[branch_name] = eval_result
                
            except Exception as e:
                self.logger.error(f"åˆ†æ”¯ {branch_name} è¯„ä¼°å¤±è´¥: {e}")
                evaluation_results[branch_name] = {"error": str(e)}
        
        # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
        comparison_report = self._generate_comparison_report(evaluation_results)
        evaluation_results['comparison'] = comparison_report
        
        return evaluation_results
    
    def _create_evaluator(self, branch_name: str, training_result: TrainingResult):
        """åˆ›å»ºè¯„ä¼°å™¨ - å ä½ç¬¦å®ç°"""
        
        # è¿™é‡Œåº”è¯¥æ ¹æ®åˆ†æ”¯ç±»å‹åˆ›å»ºç›¸åº”çš„è¯„ä¼°å™¨
        # æš‚æ—¶è¿”å›ç®€å•çš„è¯„ä¼°å™¨ç±»
        class SimpleEvaluator:
            def __init__(self, model, branch_name):
                self.model = model
                self.branch_name = branch_name
            
            def evaluate(self, episodes: int) -> Dict[str, Any]:
                # ç®€åŒ–çš„è¯„ä¼°å®ç°
                return {
                    'branch': self.branch_name,
                    'episodes': episodes,
                    'success_rate': 0.85,  # æ¨¡æ‹Ÿæ•°æ®
                    'avg_reward': 150.0,
                    'avg_episode_length': 500
                }
        
        return SimpleEvaluator(training_result.trained_model, branch_name)
    
    def _generate_comparison_report(self, evaluation_results: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
        
        # æå–å…³é”®æŒ‡æ ‡
        metrics = ['success_rate', 'avg_reward', 'avg_episode_length']
        comparison = {}
        
        for metric in metrics:
            comparison[metric] = {}
            for branch_name, result in evaluation_results.items():
                if isinstance(result, dict) and metric in result:
                    comparison[metric][branch_name] = result[metric]
        
        # æ’å
        rankings = {}
        for metric in metrics:
            if comparison[metric]:
                sorted_branches = sorted(
                    comparison[metric].items(),
                    key=lambda x: x[1],
                    reverse=True
                )
                rankings[metric] = [branch for branch, _ in sorted_branches]
        
        return {
            'metrics_comparison': comparison,
            'rankings': rankings,
            'best_overall': self._determine_best_branch(rankings)
        }
    
    def _determine_best_branch(self, rankings: Dict[str, List[str]]) -> str:
        """ç¡®å®šæœ€ä½³åˆ†æ”¯"""
        
        # ç®€å•çš„ç»¼åˆè¯„åˆ†
        branch_scores = {}
        
        for metric, ranking in rankings.items():
            for i, branch in enumerate(ranking):
                if branch not in branch_scores:
                    branch_scores[branch] = 0
                branch_scores[branch] += len(ranking) - i
        
        if branch_scores:
            best_branch = max(branch_scores.items(), key=lambda x: x[1])[0]
            return best_branch
        
        return "unknown"
    
    def _load_trainer_class(self, trainer_name: str, stage: TrainingStage):
        """åŠ¨æ€åŠ è½½è®­ç»ƒå™¨ç±» - å ä½ç¬¦å®ç°"""
        
        # è¿™é‡Œåº”è¯¥æ ¹æ®trainer_nameåŠ¨æ€å¯¼å…¥ç›¸åº”çš„è®­ç»ƒå™¨ç±»
        # æš‚æ—¶è¿”å›Mockå®ç°
        
        class MockTrainer:
            def __init__(self, config=None, env_factory=None, transfer_manager=None, 
                        foundation_checkpoint=None, output_dir=None):
                self.config = config or {}
                self.env_factory = env_factory
                self.stage = stage
                
            def train(self) -> TrainingResult:
                # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
                import time
                time.sleep(1)  # æ¨¡æ‹Ÿè®­ç»ƒæ—¶é—´
                
                # åˆ›å»ºMockæ¨¡å‹
                import torch.nn as nn
                mock_model = nn.Sequential(
                    nn.Linear(86, 128),
                    nn.ReLU(),
                    nn.Linear(128, 4)
                )
                
                return TrainingResult(
                    success=True,
                    trained_model=mock_model,
                    metrics={'final_reward': 100.0},
                    metadata={'stage': stage.value}
                )
            
            def add_progress_callback(self, callback):
                pass
        
        return MockTrainer
    
    def _save_pipeline_result(self, result: PipelineResult) -> None:
        """ä¿å­˜æµæ°´çº¿ç»“æœ"""
        
        # æ„å»ºå¯åºåˆ—åŒ–çš„ç»“æœæ•°æ®
        result_data = {
            'status': result.status.value,
            'total_duration': result.total_duration,
            'foundation_success': result.foundation_result.success if result.foundation_result else False,
            'branch_results': {
                name: {'success': res.success, 'metrics': res.metrics} 
                for name, res in result.branch_results.items()
            },
            'evaluation_results': result.evaluation_results,
            'error_message': result.error_message
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        result_path = self.experiment_dir / "pipeline_result.json"
        with open(result_path, 'w') as f:
            json.dump(result_data, f, indent=2)
        
        self.logger.info(f"æµæ°´çº¿ç»“æœå·²ä¿å­˜: {result_path}")
    
    def _notify_progress(self, message: str, data: Dict[str, Any]) -> None:
        """é€šçŸ¥è¿›åº¦æ›´æ–°"""
        
        for callback in self.progress_callbacks:
            try:
                callback(message, data)
            except Exception as e:
                self.logger.warning(f"è¿›åº¦å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
        
        self.logger.info(f"æµæ°´çº¿è¿›åº¦: {message}")
    
    def run_sequential_training(self) -> Dict[str, TrainingResult]:
        """
        æ‰§è¡Œé¡ºåºè®­ç»ƒæµç¨‹
        
        Returns:
            å„é˜¶æ®µè®­ç»ƒç»“æœ
        """
        self.logger.info("ğŸš€ å¼€å§‹é¡ºåºè®­ç»ƒæµç¨‹")
        
        try:
            # é€é˜¶æ®µæ‰§è¡Œè®­ç»ƒ
            stages = [TrainingStage.HIERARCHICAL, TrainingStage.ABLATION, TrainingStage.BASELINE]
            
            for stage in stages:
                self.logger.info(f"ğŸ¯ å¼€å§‹é˜¶æ®µ: {stage.value}")
                
                # æ‰§è¡Œå•ä¸ªé˜¶æ®µè®­ç»ƒ
                stage_result = self.run_stage(stage)
                
                if not stage_result.success:
                    self.logger.error(f"âŒ é˜¶æ®µ {stage.value} è®­ç»ƒå¤±è´¥ï¼Œåœæ­¢æµæ°´çº¿")
                    break
                
                self.logger.info(f"âœ… é˜¶æ®µ {stage.value} è®­ç»ƒå®Œæˆ")
            
            self.logger.info("ğŸ‰ é¡ºåºè®­ç»ƒæµç¨‹å®Œæˆ")
            return {}
            
        except Exception as e:
            self.logger.error(f"ğŸ’¥ è®­ç»ƒæµæ°´çº¿å¼‚å¸¸: {e}")
            raise
    
    def run_stage(self, stage: TrainingStage) -> TrainingResult:
        """
        æ‰§è¡Œå•ä¸ªè®­ç»ƒé˜¶æ®µ
        
        Args:
            stage: è®­ç»ƒé˜¶æ®µ
            
        Returns:
            è®­ç»ƒç»“æœ
        """
        # åˆ›å»ºå¯¹åº”çš„è®­ç»ƒå™¨
        from training.branches.hierarchical_trainer import HierarchicalTrainer
        from training.branches.ablation_trainer import AblationTrainer
        from training.branches.baseline_trainer import BaselineTrainer
        
        config = {
            'total_timesteps': 1000,
            'drone_model': 'CF2X',
            'physics': 'PYB',
            'gui_training': False
        }
        
        if stage == TrainingStage.HIERARCHICAL:
            trainer = HierarchicalTrainer(config=config)
        elif stage == TrainingStage.ABLATION:
            trainer = AblationTrainer(config=config)
        elif stage == TrainingStage.BASELINE:
            trainer = BaselineTrainer(config=config)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è®­ç»ƒé˜¶æ®µ: {stage}")
        
        try:
            # æ‰§è¡Œè®­ç»ƒ
            with trainer:
                result = trainer.train()
                return result
                
        except Exception as e:
            self.logger.error(f"âŒ é˜¶æ®µ {stage.value} è®­ç»ƒå¼‚å¸¸: {e}")
            
            # åˆ›å»ºå¤±è´¥ç»“æœ
            return TrainingResult(
                stage=stage,
                success=False,
                total_steps=0,
                total_episodes=0,
                final_reward=0.0,
                best_reward=0.0,
                training_time=0.0,
                model_path=None,
                metrics={},
                error_message=str(e)
            )
    
    def validate_stage_transition(self, 
                                 from_stage: TrainingStage, 
                                 to_stage: TrainingStage) -> bool:
        """éªŒè¯é˜¶æ®µè½¬æ¢çš„æœ‰æ•ˆæ€§"""
        # Foundationé˜¶æ®µå¿…é¡»æ˜¯èµ·ç‚¹
        valid_transitions = {
            TrainingStage.FOUNDATION: [TrainingStage.HIERARCHICAL, TrainingStage.ABLATION, TrainingStage.BASELINE],
            TrainingStage.HIERARCHICAL: [TrainingStage.ABLATION, TrainingStage.BASELINE]
        }
        
        if from_stage in valid_transitions:
            return to_stage in valid_transitions[from_stage]
        
        return False
    
    def get_pipeline_status(self) -> Dict[str, Any]:
        """è·å–æµæ°´çº¿çŠ¶æ€"""
        
        return {
            'status': self.status.value,
            'experiment_name': self.config.experiment_name,
            'start_time': self.start_time,
            'duration': time.time() - self.start_time if self.start_time else 0,
            'foundation_ready': self.foundation_checkpoint is not None
        }
    
    def cleanup(self) -> None:
        """æ¸…ç†èµ„æº"""
        
        # æ¸…ç†ç¯å¢ƒ
        self.env_factory.cleanup_environments()
        
        # æ¸…ç†è®­ç»ƒå™¨ç¼“å­˜
        self._trainer_cache.clear()
        
        self.logger.info("æµæ°´çº¿èµ„æºå·²æ¸…ç†")
