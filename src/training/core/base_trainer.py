#!/usr/bin/env python3

"""
åŸºç¡€è®­ç»ƒå™¨æŠ½è±¡ç±» - é›†æˆæ™ºèƒ½ä¼šè¯ç®¡ç†å’Œå¯è§†åŒ–ç³»ç»Ÿ
"""

import time
import logging
from abc import ABC, abstractmethod
from enum import Enum
from pathlib import Path
from typing import Dict, Any, Optional
from dataclasses import dataclass

# å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
SessionManager = None
TrainingVisualizationManager = None


class TrainingStage(Enum):
    """è®­ç»ƒé˜¶æ®µæšä¸¾"""
    FOUNDATION = "foundation"
    HIERARCHICAL = "hierarchical"
    ABLATION = "ablation"
    BASELINE = "baseline"


@dataclass
class TrainingResult:
    """æ ‡å‡†åŒ–çš„è®­ç»ƒç»“æœ"""
    stage: TrainingStage
    success: bool
    total_steps: int
    total_episodes: int
    final_reward: float
    best_reward: float
    training_time: float
    model_path: Optional[Path]
    metrics: Dict[str, Any]
    error_message: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'stage': self.stage.value,
            'success': self.success,
            'total_steps': self.total_steps,
            'total_episodes': self.total_episodes,
            'final_reward': self.final_reward,
            'best_reward': self.best_reward,
            'training_time': self.training_time,
            'model_path': str(self.model_path) if self.model_path else None,
            'metrics': self.metrics,
            'error_message': self.error_message
        }


class BaseTrainer(ABC):
    """
    åŸºç¡€è®­ç»ƒå™¨æŠ½è±¡ç±» - é›†æˆæ™ºèƒ½ä¼šè¯ç®¡ç†å’Œé˜¶æ®µæ„ŸçŸ¥å¯è§†åŒ–
    
    æä¾›ç»Ÿä¸€çš„è®­ç»ƒæ¥å£ï¼Œè‡ªåŠ¨é›†æˆï¼š
    - SessionManager: æ™ºèƒ½ç›®å½•ç®¡ç†å’Œæ•°æ®ä¿å­˜
    - VisualizationManager: é˜¶æ®µæ„ŸçŸ¥çš„å®æ—¶å¯è§†åŒ–
    """
    
    def __init__(self, 
                 stage: TrainingStage, 
                 config: Dict[str, Any],
                 experiment_name: str = "HA-UAV",
                 stage_variant: Optional[str] = None):
        """
        åˆå§‹åŒ–åŸºç¡€è®­ç»ƒå™¨
        
        Args:
            stage: è®­ç»ƒé˜¶æ®µ
            config: è®­ç»ƒé…ç½®
            experiment_name: å®éªŒåç§°
            stage_variant: é˜¶æ®µå˜ä½“ï¼ˆå¦‚B1/B2/B3ã€ppo/sacç­‰ï¼‰
        """
        self.stage = stage
        self.config = config
        self.experiment_name = experiment_name
        self.stage_variant = stage_variant
        self.logger = logging.getLogger(f"{__name__}.{stage.value}")
        
        # ç®¡ç†å™¨å®ä¾‹
        self.session_manager = None
        self.visualization_manager = None
        
        # è®­ç»ƒçŠ¶æ€
        self.training_start_time = None
        self.best_reward = float('-inf')
        self.current_step = 0
        self.current_episode = 0
        
        # æ€§èƒ½è¿½è¸ª
        self.training_metrics = {}
        self.evaluation_history = []
    
    def initialize_session(self, 
                          enable_trajectory: bool = True,
                          enable_tensorboard: bool = True,
                          enable_visualization: bool = True,
                          enable_pointcloud: bool = False,
                          enable_analysis: bool = False,
                          enable_rich_display: bool = True):
        """
        åˆå§‹åŒ–ä¼šè¯ç®¡ç†å™¨å’Œå¯è§†åŒ–ç®¡ç†å™¨
        
        Args:
            enable_*: å„ç§åŠŸèƒ½æ¨¡å—çš„å¯ç”¨æ ‡å¿—
            enable_rich_display: æ˜¯å¦å¯ç”¨ä¸°å¯Œçš„å¯è§†åŒ–æ˜¾ç¤º
        """
        # å»¶è¿Ÿå¯¼å…¥
        global SessionManager, TrainingVisualizationManager
        if SessionManager is None:
            from .session_manager import SessionManager
        if TrainingVisualizationManager is None:
            from .visualization_manager import TrainingVisualizationManager
        
        # åˆå§‹åŒ–ä¼šè¯ç®¡ç†å™¨
        self.session_manager = SessionManager(
            experiment_name=self.experiment_name,
            training_stage=self.stage,
            config=self.config,
            stage_variant=self.stage_variant,
            enable_trajectory=enable_trajectory,
            enable_tensorboard=enable_tensorboard,
            enable_visualization=enable_visualization,
            enable_pointcloud=enable_pointcloud,
            enable_analysis=enable_analysis
        )
        
        # åˆå§‹åŒ–å¯è§†åŒ–ç®¡ç†å™¨
        if enable_visualization:
            total_steps = self.config.get('total_timesteps', 100000)
            eval_freq = self.config.get('evaluation_frequency', 10000)
            
            self.visualization_manager = TrainingVisualizationManager(
                total_steps=total_steps,
                training_stage=self.stage,
                experiment_name=self.experiment_name,
                stage_variant=self.stage_variant,
                evaluation_frequency=eval_freq,
                enable_rich_display=enable_rich_display
            )
        
        self.logger.info(f"âœ… {self.stage.value} è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
        
        # è¿”å›ä¼šè¯ä¿¡æ¯ä¾›å­ç±»ä½¿ç”¨
        return self.session_manager.get_session_info()
    
    @abstractmethod
    def setup(self) -> bool:
        """è®¾ç½®è®­ç»ƒç¯å¢ƒå’Œæ¨¡å‹ - å­ç±»å¿…é¡»å®ç°"""
        pass
    
    def train(self) -> TrainingResult:
        """
        æ‰§è¡Œè®­ç»ƒè¿‡ç¨‹ - é›†æˆå®Œæ•´çš„ä¼šè¯ç®¡ç†å’Œå¯è§†åŒ–
        
        Returns:
            TrainingResult: æ ‡å‡†åŒ–çš„è®­ç»ƒç»“æœ
        """
        
        # å¦‚æœæœªåˆå§‹åŒ–ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®
        if not self.session_manager:
            self.initialize_session()
        
        # ğŸ”§ é¦–å…ˆè®¾ç½®è®­ç»ƒå™¨ï¼ˆè°ƒç”¨å­ç±»çš„setupæ–¹æ³•ï¼‰
        if not self.setup():
            return TrainingResult(
                stage=self.stage,
                success=False,
                total_steps=0,
                total_episodes=0,
                final_reward=0.0,
                best_reward=0.0,
                training_time=0.0,
                model_path=Path(""),
                metrics={},
                error_message="è®­ç»ƒå™¨è®¾ç½®å¤±è´¥"
            )
        
        self.training_start_time = time.time()
        
        try:
            # è®­ç»ƒå¼€å§‹å›è°ƒ
            if self.visualization_manager:
                config_summary = self._get_config_summary()
                self.visualization_manager.on_training_start(config_summary)
            
            # æ‰§è¡Œå®é™…è®­ç»ƒ
            training_metrics = self._execute_training()
            
            # è®¡ç®—è®­ç»ƒæ—¶é—´
            training_time = time.time() - self.training_start_time
            
            # ä¿å­˜æœ€ç»ˆæ¨¡å‹
            model_path = self._save_final_model()
            
            # æœ€ç»ˆè¯„ä¼°
            final_eval = self._perform_final_evaluation()
            training_metrics.update(final_eval)
            
            # åˆ›å»ºè®­ç»ƒç»“æœ
            result = TrainingResult(
                stage=self.stage,
                success=True,
                total_steps=self.current_step,
                total_episodes=self.current_episode,
                final_reward=training_metrics.get('final_mean_reward', training_metrics.get('avg_episode_reward', 0.0)),
                best_reward=self.best_reward,
                training_time=training_time,
                model_path=model_path,
                metrics=training_metrics
            )
            
            # ä¿å­˜è®­ç»ƒç»“æœ
            if self.session_manager:
                self.session_manager.save_training_results(training_metrics)
            
            # è®­ç»ƒç»“æŸå›è°ƒ
            if self.visualization_manager:
                final_stats = {
                    'best_score': self.best_reward,
                    'final_reward': training_metrics.get('final_mean_reward', training_metrics.get('avg_episode_reward', 0.0)),
                    'total_episodes': self.current_episode,
                    'training_time': f"{training_time:.1f}s",
                    'model_path': str(model_path),
                    'final_success_rate': training_metrics.get('final_success_rate', training_metrics.get('success_rate', 0.0))
                }
                self.visualization_manager.on_training_end(final_stats)
            
            self.logger.info(f"âœ… {self.stage.value} è®­ç»ƒæˆåŠŸå®Œæˆ")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ {self.stage.value} è®­ç»ƒå¤±è´¥: {e}")
            
            # è®­ç»ƒå¤±è´¥çš„ç»“æœ
            return TrainingResult(
                stage=self.stage,
                success=False,
                total_steps=self.current_step,
                total_episodes=self.current_episode,
                final_reward=0.0,
                best_reward=self.best_reward,
                training_time=time.time() - self.training_start_time if self.training_start_time else 0.0,
                model_path=Path(""),
                metrics={'error': str(e)},
                error_message=str(e)
            )
        finally:
            # æ¸…ç†èµ„æº
            self.cleanup()
    
    @abstractmethod
    def _execute_training(self) -> Dict[str, Any]:
        """æ‰§è¡Œå®é™…è®­ç»ƒé€»è¾‘ - å­ç±»å¿…é¡»å®ç°"""
        pass
    
    @abstractmethod
    def evaluate(self, num_episodes: int = 100) -> Dict[str, float]:
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½ - å­ç±»å¿…é¡»å®ç°"""
        pass
    
    @abstractmethod
    def save_model(self, path: Path) -> bool:
        """ä¿å­˜è®­ç»ƒæ¨¡å‹ - å­ç±»å¿…é¡»å®ç°"""
        pass
    
    @abstractmethod
    def load_model(self, path: Path) -> bool:
        """åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ - å­ç±»å¿…é¡»å®ç°"""
        pass
    
    def _perform_final_evaluation(self) -> Dict[str, Any]:
        """æ‰§è¡Œæœ€ç»ˆè¯„ä¼°"""
        try:
            final_eval_episodes = self.config.get('final_eval_episodes', 5)  # å‡å°‘ä¸º5
            
            if self.visualization_manager:
                self.visualization_manager.write_stage_message("å¼€å§‹æœ€ç»ˆè¯„ä¼°...")
            
            final_eval_results = self.evaluate(final_eval_episodes)
            
            # æ·»åŠ final_å‰ç¼€åŒºåˆ†æœ€ç»ˆè¯„ä¼°
            final_results = {}
            for key, value in final_eval_results.items():
                final_results[f'final_{key}'] = value
            
            if self.visualization_manager:
                self.visualization_manager.write_stage_message(
                    f"æœ€ç»ˆè¯„ä¼°å®Œæˆ - å¥–åŠ±: {final_eval_results.get('mean_reward', 0.0):.3f}"
                )
            
            return final_results
            
        except Exception as e:
            self.logger.error(f"æœ€ç»ˆè¯„ä¼°å¤±è´¥: {e}")
            return {'final_evaluation_error': str(e)}
    
    def _save_final_model(self) -> Path:
        """ä¿å­˜æœ€ç»ˆæ¨¡å‹"""
        if self.session_manager:
            model_path = self.session_manager.get_model_save_path("final_model")
            self.save_model(model_path)
            
            if self.visualization_manager:
                self.visualization_manager.on_model_save(
                    "æœ€ç»ˆ", 
                    self.best_reward, 
                    str(model_path)
                )
            
            return model_path
        else:
            # é»˜è®¤è·¯å¾„
            model_path = Path(f"{self.stage.value}_final_model.zip")
            self.save_model(model_path)
            return model_path
    
    def _get_config_summary(self) -> Dict[str, Any]:
        """è·å–é…ç½®æ‘˜è¦ç”¨äºæ˜¾ç¤º"""
        summary = {
            'total_timesteps': self.config.get('total_timesteps', 100000),
            'evaluation_frequency': self.config.get('evaluation_frequency', 10000),
            'learning_rate': self.config.get('learning_rate', 3e-4),
            'batch_size': self.config.get('batch_size', 128),
            'foundation_model_path': self.config.get('foundation_model_path') is not None
        }
        
        # æ ¹æ®è®­ç»ƒé˜¶æ®µè®¾ç½®ä¸åŒçš„é…ç½®ä¿¡æ¯
        if self.stage == TrainingStage.FOUNDATION:
            # åŸºåº§æ¨¡å‹ä½¿ç”¨PPOå‚æ•°
            summary.update({
                'buffer_size': self.config.get('buffer_size', self.config.get('n_steps', 2048)),
                'network_arch': self.config.get('network_arch', 'PPO-MLP'),
            })
        elif self.stage == TrainingStage.HIERARCHICAL:
            # åˆ†å±‚æ¨¡å‹å‚æ•°
            summary.update({
                'buffer_size': self.config.get('buffer_size', 100000),
                'network_arch': self.config.get('network_arch', 'HA-UAV-Hierarchical'),
                'high_level_update_frequency': self.config.get('high_level_update_frequency', 10),
                'future_horizon': self.config.get('future_horizon', 5)
            })
        elif self.stage == TrainingStage.ABLATION:
            # æ¶ˆèç ”ç©¶å‚æ•°
            summary.update({
                'buffer_size': self.config.get('buffer_size', 100000),
                'network_arch': self.config.get('network_arch', 'HA-UAV-Ablation'),
                'high_level_update_frequency': self.config.get('high_level_update_frequency', 10),
                'future_horizon': self.config.get('future_horizon', 5),
                'ablation_type': self.stage_variant or self.config.get('ablation_type', 'N/A')
            })
        elif self.stage == TrainingStage.BASELINE:
            # åŸºçº¿ç®—æ³•å‚æ•°
            summary.update({
                'buffer_size': self.config.get('buffer_size', 1000000),
                'network_arch': self.config.get('network_arch', 'SAC/TD3-MLP'),
                'algorithm': self.stage_variant or self.config.get('algorithm', 'N/A')
            })
        else:
            # é»˜è®¤å‚æ•°
            summary.update({
                'buffer_size': self.config.get('buffer_size', 'N/A'),
                'network_arch': self.config.get('network_arch', 'N/A'),
            })
        
        # æ·»åŠ ä¼šè¯ç®¡ç†å™¨çš„åŠŸèƒ½çŠ¶æ€
        if self.session_manager:
            feature_flags = self.session_manager.feature_flags
            summary.update({
                'tensorboard_enabled': feature_flags.get('tensorboard', False),
                'trajectory_enabled': feature_flags.get('trajectory', False)
            })
        
        return summary
    
    # === å›è°ƒæ¥å£ ===
    
    def on_step_callback(self, step: int, metrics: Dict[str, Any]):
        """æ­¥éª¤å›è°ƒ - æ›´æ–°å¯è§†åŒ–å’ŒæŒ‡æ ‡"""
        self.current_step = step
        self.training_metrics.update(metrics)
        
        if self.visualization_manager:
            self.visualization_manager.on_step(step, metrics)
    
    def on_episode_callback(self, episode: int, metrics: Dict[str, Any]):
        """Episodeå›è°ƒ"""
        self.current_episode = episode
        self.training_metrics.update(metrics)
        
        if self.visualization_manager:
            self.visualization_manager.on_episode_end(episode, metrics)
    
    def on_evaluation_callback(self, eval_metrics: Dict[str, float]):
        """è¯„ä¼°å›è°ƒ"""
        # è®°å½•è¯„ä¼°å†å²
        eval_record = {
            'step': self.current_step,
            'episode': self.current_episode,
            'metrics': eval_metrics.copy()
        }
        self.evaluation_history.append(eval_record)
        
        # æ›´æ–°æœ€ä½³å¥–åŠ±
        if 'mean_reward' in eval_metrics:
            if eval_metrics['mean_reward'] > self.best_reward:
                self.best_reward = eval_metrics['mean_reward']
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                if self.session_manager:
                    best_model_path = self.session_manager.get_model_save_path("best_model")
                    self.save_model(best_model_path)
                    
                    if self.visualization_manager:
                        self.visualization_manager.on_model_save(
                            "æœ€ä½³", 
                            self.best_reward,
                            str(best_model_path)
                        )
        
        if self.visualization_manager:
            self.visualization_manager.on_evaluation_end(eval_metrics)
    
    def on_checkpoint_callback(self, step: int):
        """æ£€æŸ¥ç‚¹ä¿å­˜å›è°ƒ"""
        if self.session_manager:
            checkpoint_path = self.session_manager.get_checkpoint_path(step)
            
            try:
                self.save_model(checkpoint_path)
                
                if self.visualization_manager:
                    self.visualization_manager.on_checkpoint_save(step, str(checkpoint_path))
                
                self.logger.info(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")
                
            except Exception as e:
                self.logger.error(f"æ£€æŸ¥ç‚¹ä¿å­˜å¤±è´¥: {e}")
    
    # === æ•°æ®é“¾è·¯æ¥å£ ===
    
    def get_session_paths(self) -> Dict[str, Path]:
        """è·å–ä¼šè¯è·¯å¾„"""
        if self.session_manager:
            return self.session_manager.get_session_paths()
        return {}
    
    def get_tensorboard_log_dir(self, mode: str = "train") -> Optional[Path]:
        """è·å–TensorBoardæ—¥å¿—ç›®å½•"""
        if self.session_manager:
            return self.session_manager.get_tensorboard_log_dir(mode)
        return None
    
    def get_trajectory_manager(self, mode: str = "train"):
        """è·å–è½¨è¿¹ç®¡ç†å™¨"""
        if self.session_manager:
            return self.session_manager.get_trajectory_manager(mode)
        return None
    
    def save_analysis_data(self, data: Dict[str, Any], filename: str):
        """ä¿å­˜åˆ†ææ•°æ®"""
        if self.session_manager:
            self.session_manager.save_analysis_data(data, filename)
    
    def save_visualization_data(self, data: Dict[str, Any], filename: str):
        """ä¿å­˜å¯è§†åŒ–æ•°æ®"""
        if self.session_manager:
            self.session_manager.save_visualization_data(data, filename)
    
    def write_message(self, message: str, level: str = "INFO"):
        """å†™å…¥æ¶ˆæ¯åˆ°å¯è§†åŒ–ç•Œé¢"""
        if self.visualization_manager:
            self.visualization_manager.write_message(message, level)
        else:
            getattr(self.logger, level.lower(), self.logger.info)(message)
    
    def write_stage_message(self, message: str):
        """å†™å…¥é˜¶æ®µç‰¹å®šæ¶ˆæ¯"""
        if self.visualization_manager:
            self.visualization_manager.write_stage_message(message)
        else:
            self.logger.info(f"[{self.stage.value}] {message}")
    
    # === èµ„æºç®¡ç† ===
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.session_manager:
            self.session_manager.close()
        
        if self.visualization_manager:
            self.visualization_manager.close()
    
    def __enter__(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        self.cleanup()


# ä¾¿æ·å·¥å‚å‡½æ•°
class TrainerFactory:
    """è®­ç»ƒå™¨å·¥å‚ç±»"""
    
    _trainers = {}
    
    @classmethod
    def register(cls, stage: TrainingStage, trainer_class):
        """æ³¨å†Œè®­ç»ƒå™¨ç±»"""
        cls._trainers[stage] = trainer_class
    
    @classmethod
    def create(cls, stage: TrainingStage, config: Dict[str, Any], **kwargs):
        """åˆ›å»ºè®­ç»ƒå™¨å®ä¾‹"""
        if stage not in cls._trainers:
            raise ValueError(f"æœªæ³¨å†Œçš„è®­ç»ƒé˜¶æ®µ: {stage}")
        
        return cls._trainers[stage](config=config, **kwargs)


# è¿›åº¦å›è°ƒç±»
class TrainingProgressCallback:
    """è®­ç»ƒè¿›åº¦å›è°ƒæ¥å£"""
    
    def __init__(self, trainer: BaseTrainer):
        self.trainer = trainer
    
    def on_step(self, step: int, metrics: Dict[str, Any]):
        """æ­¥éª¤å›è°ƒ"""
        self.trainer.on_step_callback(step, metrics)
    
    def on_episode_end(self, episode: int, metrics: Dict[str, Any]):
        """Episodeç»“æŸå›è°ƒ"""
        self.trainer.on_episode_callback(episode, metrics)
    
    def on_evaluation_end(self, eval_metrics: Dict[str, float]):
        """è¯„ä¼°ç»“æŸå›è°ƒ"""
        self.trainer.on_evaluation_callback(eval_metrics)
    
    def on_checkpoint_save(self, step: int):
        """æ£€æŸ¥ç‚¹ä¿å­˜å›è°ƒ"""
        self.trainer.on_checkpoint_callback(step)
    
    @abstractmethod
    def evaluate(self, num_episodes: int = 10) -> Dict[str, Any]:
        """
        è¯„ä¼°æ¨¡å‹æ€§èƒ½
        
        Args:
            num_episodes: è¯„ä¼°è½®æ•°
            
        Returns:
            Dict[str, Any]: è¯„ä¼°ç»“æœ
        """
        pass
    
    @abstractmethod
    def save_model(self, path: Path, metadata: Optional[Dict] = None) -> bool:
        """
        ä¿å­˜æ¨¡å‹
        
        Args:
            path: ä¿å­˜è·¯å¾„
            metadata: é¢å¤–å…ƒæ•°æ®
            
        Returns:
            bool: æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        pass
    
    @abstractmethod
    def load_model(self, path: Path) -> bool:
        """
        åŠ è½½æ¨¡å‹
        
        Args:
            path: æ¨¡å‹è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        pass
    
    def cleanup(self) -> None:
        """æ¸…ç†èµ„æº"""
        try:
            if self.env is not None:
                self.env.close()
            self.logger.info(f"{self.stage.value} è®­ç»ƒå™¨èµ„æºæ¸…ç†å®Œæˆ")
        except Exception as e:
            self.logger.error(f"èµ„æºæ¸…ç†æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    def get_training_summary(self) -> Dict[str, Any]:
        """è·å–è®­ç»ƒæ‘˜è¦"""
        training_time = time.time() - self.start_time if self.start_time else 0
        
        return {
            'stage': self.stage.value,
            'current_step': self.current_step,
            'current_episode': self.current_episode,
            'best_score': self.best_score,
            'training_time': training_time,
            'is_initialized': self.is_initialized,
            'metrics': self.training_metrics.copy()
        }
    
    def log_progress(self, step: int, metrics: Dict[str, Any]) -> None:
        """è®°å½•è®­ç»ƒè¿›åº¦"""
        self.current_step = step
        self.training_metrics.update(metrics)
        
        # æ”¹ä¸ºåŸºäºé—´éš”çš„æ—¥å¿—è®°å½•
        steps_since_last_log = step - getattr(self, '_last_log_step', 0)
        if steps_since_last_log >= 10000 and step > 0:  # æ¯10kæ­¥è®°å½•ä¸€æ¬¡
            self._last_log_step = step
            self.logger.info(
                f"[{self.stage.value}] Step {step}: "
                f"Episode {self.current_episode}, "
                f"Best Score {self.best_score:.3f}"
            )
    
    def _validate_config(self) -> bool:
        """éªŒè¯é…ç½®æœ‰æ•ˆæ€§"""
        required_keys = ['total_steps', 'eval_freq', 'save_freq']
        
        for key in required_keys:
            if key not in self.config:
                self.logger.error(f"é…ç½®ç¼ºå°‘å¿…éœ€å‚æ•°: {key}")
                return False
        
        return True
    
    def _create_session_paths(self) -> Dict[str, Path]:
        """åˆ›å»ºä¼šè¯è·¯å¾„ï¼ˆå¤ç”¨ç°æœ‰session_managerï¼‰"""
        if self.session_manager:
            return self.session_manager.get_session_paths()
        else:
            # ç®€å•è·¯å¾„åˆ›å»º
            base_path = Path("./logs") / f"{self.stage.value}_session"
            base_path.mkdir(parents=True, exist_ok=True)
            
            return {
                'session': base_path,
                'models': base_path / 'models',
                'results': base_path / 'results',
                'plots': base_path / 'plots'
            }


class TrainerFactory:
    """è®­ç»ƒå™¨å·¥å‚ - æ ¹æ®é˜¶æ®µåˆ›å»ºç›¸åº”çš„è®­ç»ƒå™¨"""
    
    @staticmethod
    def create_trainer(stage: TrainingStage, 
                      config: Dict[str, Any], 
                      session_manager=None, 
                      **kwargs) -> BaseTrainer:
        """
        åˆ›å»ºè®­ç»ƒå™¨å®ä¾‹
        
        Args:
            stage: è®­ç»ƒé˜¶æ®µ
            config: é…ç½®
            session_manager: ä¼šè¯ç®¡ç†å™¨
            **kwargs: é¢å¤–å‚æ•°
            
        Returns:
            BaseTrainer: å¯¹åº”çš„è®­ç»ƒå™¨å®ä¾‹
        """
        if stage == TrainingStage.FOUNDATION:
            from ..foundation.baseflight_trainer import BaseFlightTrainer
            return BaseFlightTrainer(stage, config, session_manager, **kwargs)
            
        elif stage == TrainingStage.HIERARCHICAL:
            from ..branches.hierarchical_trainer import HierarchicalTrainer
            return HierarchicalTrainer(stage, config, session_manager, **kwargs)
            
        elif stage == TrainingStage.ABLATION:
            from ..branches.ablation_trainer import AblationTrainer
            return AblationTrainer(stage, config, session_manager, **kwargs)
            
        elif stage == TrainingStage.BASELINE:
            from ..branches.baseline_trainer import BaselineTrainer
            return BaselineTrainer(stage, config, session_manager, **kwargs)
            
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è®­ç»ƒé˜¶æ®µ: {stage}")


class TrainingProgressCallback:
    """è®­ç»ƒè¿›åº¦å›è°ƒ - å¤ç”¨ç°æœ‰visualization_managerçš„æ¦‚å¿µ"""
    
    def __init__(self, trainer: BaseTrainer):
        self.trainer = trainer
        self.logger = trainer.logger
    
    def on_training_start(self) -> None:
        """è®­ç»ƒå¼€å§‹å›è°ƒ"""
        self.logger.info(f"å¼€å§‹ {self.trainer.stage.value} é˜¶æ®µè®­ç»ƒ")
        self.trainer.start_time = time.time()
    
    def on_step(self, step: int, metrics: Dict[str, Any]) -> None:
        """æ­¥éª¤å›è°ƒ"""
        self.trainer.log_progress(step, metrics)
    
    def on_episode_end(self, episode: int, reward: float) -> None:
        """Episodeç»“æŸå›è°ƒ"""
        self.trainer.current_episode = episode
        if reward > self.trainer.best_score:
            self.trainer.best_score = reward
    
    def on_evaluation(self, eval_results: Dict[str, Any]) -> None:
        """è¯„ä¼°å›è°ƒ"""
        self.logger.info(f"è¯„ä¼°ç»“æœ: {eval_results}")
    
    def on_training_end(self, results: TrainingResult) -> None:
        """è®­ç»ƒç»“æŸå›è°ƒ"""
        self.logger.info(
            f"{self.trainer.stage.value} è®­ç»ƒå®Œæˆ: "
            f"æˆåŠŸ={results.success}, "
            f"æ€»æ­¥æ•°={results.total_steps}, "
            f"æœ€ä½³å¥–åŠ±={results.best_reward:.3f}"
        )
